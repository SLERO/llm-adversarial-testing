# llm-adversarial-testing
This project demonstrates how structured counter-narratives and historical context can bypass LLM safety filters and elicit more nuanced responses on sensitive topics.

Проблема. Жесткие идеологические фильтры в ИИ, которые мешают объективному анализу.

Метод. Последовательное предъявление верифицированных исторических фактов и контраргументов. 


